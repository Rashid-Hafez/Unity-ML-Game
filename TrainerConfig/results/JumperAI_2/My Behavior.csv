Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,High Score,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
50000,0.68660855,-0.10377623,252.99462365591398,-0.8930107465274232,-0.8930107465274232,7.0,0.021982333,0.023489729,0.00028457041,0.1948568,0.004743354,1.0
100000,0.6915054,-0.17016141,254.2153846153846,-0.8917948662852629,-0.8917948662852629,8.0,0.01939708,0.022339238,0.0002567315,0.18557718,0.0042803,1.0
150000,0.6889852,-0.18138327,246.66826923076923,-0.9004807644165479,-0.9004807644165479,9.0,0.019037899,0.023460092,0.00022591926,0.1753064,0.003767789,1.0
200000,0.6760763,-0.20760542,242.67149758454107,-0.9048309134328423,-0.9048309134328423,None,0.018971462,0.022229174,0.00019508679,0.16502891,0.003254943,1.0
250000,0.6756382,-0.22709645,231.95283018867926,-0.9033018806070652,-0.9033018806070652,None,0.018241173,0.024981204,0.00016423807,0.154746,0.0027418253,1.0
300000,0.6495878,-0.24766631,242.49756097560976,-0.899999994475667,-0.899999994475667,None,0.016696563,0.023983676,0.00013343577,0.14447856,0.0022294803,1.0
350000,0.6568785,-0.22946192,239.9047619047619,-0.9063414591841581,-0.9063414591841581,None,0.017859058,0.022131715,0.000102611855,0.13420391,0.0017167755,1.0
400000,0.6770433,-0.23109376,243.81,-0.8975609696129473,-0.8975609696129473,None,0.017412197,0.023319535,7.484289e-05,0.12494761,0.001254885,1.0
450000,0.6760967,-0.23169045,235.11004784688996,-0.9047846835124436,-0.9047846835124436,11.0,0.017523212,0.023228262,4.707861e-05,0.11569284,0.0007930727,1.0
500000,0.6771052,-0.23892693,230.6027397260274,-0.9109588991085144,-0.9109588991085144,None,0.018228132,0.024011951,1.6255175e-05,0.10541835,0.00028037615,1.0
