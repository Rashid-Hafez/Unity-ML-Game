Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,High Score,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
50000,0.67998123,-0.022699853,247.4784946236559,-0.8983870905733877,-0.8983870905733877,8.0,0.027878504,0.02234319,0.00028457431,0.19485812,0.0047434196,1.0
100000,0.6663415,-0.14770117,268.7864583333333,-0.8776041605354598,-0.8776041605354598,None,0.019609593,0.022227831,0.00025683013,0.18561006,0.004281941,1.0
150000,0.6558801,-0.20620549,249.645,-0.8934999941661954,-0.8934999941661954,None,0.018637361,0.022465106,0.0002259515,0.1753172,0.003768326,1.0
200000,0.6722027,-0.22621727,240.26341463414633,-0.9034146294361207,-0.9034146294361207,None,0.01788641,0.023858076,0.00019512654,0.16504215,0.0032556034,1.0
250000,0.64918065,-0.21677522,247.1871921182266,-0.8980295517174481,-0.8980295517174481,None,0.017837418,0.026295412,0.00016432132,0.15477376,0.0027432104,1.0
300000,0.63769567,-0.22826199,235.20093457943926,-0.9079812157182067,-0.9079812157182067,None,0.01789736,0.022945274,0.00013348664,0.14449552,0.0022303262,1.0
350000,0.63890547,-0.24172175,236.94811320754718,-0.9014084446178355,-0.9014084446178355,None,0.017170668,0.021478452,0.00010268539,0.13422844,0.001717999,1.0
400000,0.6443972,-0.24530329,249.41237113402062,-0.8912371075184075,-0.8912371075184075,None,0.015956422,0.023146247,7.4924625e-05,0.12497485,0.001256245,1.0
450000,0.64270985,-0.2403195,230.4018691588785,-0.9107476587746745,-0.9107476587746745,None,0.01836592,0.024365794,4.717425e-05,0.11572473,0.00079466344,1.0
500000,0.6416426,-0.25208303,240.30143540669857,-0.9038461486522394,-0.9038461486522394,None,0.017322887,0.022256745,1.6368813e-05,0.10545625,0.0002822663,1.0
